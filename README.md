# ğŸ” LoRA Analyzer

Herramienta completa para analizar archivos LoRA (Low-Rank Adaptation) y descubrir cÃ³mo fueron entrenados.

## ğŸŒŸ CaracterÃ­sticas

- âœ… **AnÃ¡lisis completo** de arquitectura LoRA (rank, alpha, capas)
- âœ… **ExtracciÃ³n de metadatos** de entrenamiento
- âœ… **EstadÃ­sticas de pesos** y distribuciones
- âœ… **ComparaciÃ³n** de mÃºltiples LoRAs
- âœ… **Recomendaciones** para optimizaciÃ³n
- âœ… **3 interfaces diferentes**: CLI, Web App y API REST

## ğŸ“ Formatos Soportados

- `.safetensors` (recomendado)
- `.pt` / `.pth` (PyTorch)
- `.ckpt` (Checkpoints)

## ğŸš€ InstalaciÃ³n RÃ¡pida

```bash
# Clonar o descargar los archivos
cd lora-analyzer

# Instalar dependencias
pip install -r requirements.txt

# Â¡Listo para usar!
```

### InstalaciÃ³n opcional de PyTorch

Si no tienes PyTorch instalado, usa:

```bash
# CPU only
pip install torch --index-url https://download.pytorch.org/whl/cpu

# CUDA (GPU)
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

## ğŸ’» Uso

### 1ï¸âƒ£ CLI (LÃ­nea de Comandos)

La forma mÃ¡s rÃ¡pida para anÃ¡lisis desde terminal:

```bash
# Analizar un archivo
python lora_cli.py mi_lora.safetensors

# Analizar mÃºltiples archivos
python lora_cli.py lora1.safetensors lora2.pt lora3.ckpt

# Guardar resultado en JSON
python lora_cli.py mi_lora.safetensors --output resultado.json

# Comparar mÃºltiples LoRAs
python lora_cli.py lora1.safetensors lora2.safetensors --compare

# Modo verbose
python lora_cli.py mi_lora.safetensors --verbose

# Ver ayuda
python lora_cli.py --help
```

**Ejemplo de salida:**
```
ğŸ” Analizando: my_style_lora.safetensors
======================================================================
REPORTE DE ANÃLISIS LORA
======================================================================

ğŸ“ INFORMACIÃ“N DEL ARCHIVO:
  Nombre: my_style_lora.safetensors
  TamaÃ±o: 144.2 MB
  Formato: .safetensors

ğŸ—ï¸  ARQUITECTURA:
  Total de capas: 192
  Rank mÃ¡s comÃºn: 32
  Rango de ranks: 32 - 32

âš™ï¸  METADATOS DE ENTRENAMIENTO:
  Modelo base: sd_xl_base_1.0.safetensors
  Network dim (rank): 32
  Alpha: 32
  Learning rate: 0.0001
  Ã‰pocas: 10
  ImÃ¡genes de entrenamiento: 45
  Batch size: 1
  ResoluciÃ³n: 1024

ğŸ’¡ RECOMENDACIONES:
  1. Rank Ã³ptimo (32): Buen balance entre detalle y eficiencia.
  2. Dataset mediano (45 imÃ¡genes): Bueno para conceptos especÃ­ficos.
```

### 2ï¸âƒ£ Web App (Interfaz GrÃ¡fica)

Interfaz visual con Gradio - ideal para uso interactivo:

```bash
# Iniciar la aplicaciÃ³n web
python lora_webapp.py
```

Luego abre tu navegador en: **http://localhost:7860**

**Funcionalidades:**
- ğŸ“¤ Arrastrar y soltar archivos
- ğŸ“Š Vista de anÃ¡lisis con resumen visual
- ğŸ“ˆ Datos JSON completos
- âš–ï¸ ComparaciÃ³n lado a lado
- ğŸ’¾ Exportar resultados

![Web App Screenshot](https://via.placeholder.com/800x400?text=Web+App+Interface)

### 3ï¸âƒ£ API REST

Servidor FastAPI para integraciÃ³n programÃ¡tica:

```bash
# Iniciar el servidor API
python lora_api.py
```

El servidor estarÃ¡ disponible en: **http://localhost:8000**

**DocumentaciÃ³n interactiva:** http://localhost:8000/docs

#### Endpoints disponibles:

##### `POST /analyze` - Analizar un archivo

```bash
curl -X POST "http://localhost:8000/analyze" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@mi_lora.safetensors"
```

```python
import requests

with open('mi_lora.safetensors', 'rb') as f:
    response = requests.post(
        'http://localhost:8000/analyze',
        files={'file': f}
    )
    result = response.json()
    print(result)
```

##### `POST /analyze/batch` - Analizar mÃºltiples archivos

```python
import requests

files = [
    ('files', open('lora1.safetensors', 'rb')),
    ('files', open('lora2.safetensors', 'rb'))
]
response = requests.post(
    'http://localhost:8000/analyze/batch',
    files=files
)
print(response.json())
```

##### `POST /compare` - Comparar archivos

```bash
curl -X POST "http://localhost:8000/compare" \
  -F "files=@lora1.safetensors" \
  -F "files=@lora2.safetensors"
```

##### `GET /health` - Estado del servicio

```bash
curl http://localhost:8000/health
```

##### `GET /examples` - Ver mÃ¡s ejemplos

```bash
curl http://localhost:8000/examples
```

## ğŸ“Š InformaciÃ³n que Puedes Extraer

### âœ… Lo que SÃ puedes obtener:

- **Arquitectura completa**
  - DimensiÃ³n de rank (8, 16, 32, 64, 128, etc.)
  - Factor alpha de escalado
  - Capas modificadas (attention blocks, MLP, etc.)
  - Total de parÃ¡metros

- **Metadatos de entrenamiento** (si estÃ¡n incluidos)
  - Modelo base utilizado (SD 1.5, SDXL, etc.)
  - Learning rate
  - NÃºmero de epochs
  - Batch size
  - ResoluciÃ³n de entrenamiento
  - NÃºmero de imÃ¡genes de entrenamiento
  - Herramienta usada (Kohya, EveryDream, etc.)

- **EstadÃ­sticas de pesos**
  - DistribuciÃ³n de valores
  - Media y desviaciÃ³n estÃ¡ndar
  - Intensidad por capa

### âŒ Lo que NO puedes recuperar:

- **Los datos de entrenamiento originales** - TÃ©cnicamente imposible
- **ImÃ¡genes especÃ­ficas del dataset** - No estÃ¡n almacenadas en el LoRA
- **Prompts exactos usados** - Solo si estÃ¡n en metadatos

## ğŸ¯ Casos de Uso

### 1. IngenierÃ­a Inversa
```bash
# Analiza un LoRA pÃºblico para aprender de Ã©l
python lora_cli.py awesome_public_lora.safetensors

# Compara con tu propio LoRA
python lora_cli.py awesome_public_lora.safetensors my_lora.safetensors --compare
```

### 2. OptimizaciÃ³n de tus LoRAs
```bash
# Analiza diferentes versiones para encontrar la mejor configuraciÃ³n
python lora_cli.py lora_v1_rank16.safetensors lora_v2_rank32.safetensors \
                   lora_v3_rank64.safetensors --compare
```

### 3. Debugging
```bash
# Verifica que tu LoRA se entrenÃ³ correctamente
python lora_cli.py my_new_lora.safetensors --verbose
```

### 4. InvestigaciÃ³n
```python
# Analiza mÃºltiples LoRAs programÃ¡ticamente
import requests
import os

for filename in os.listdir('loras/'):
    if filename.endswith('.safetensors'):
        with open(f'loras/{filename}', 'rb') as f:
            response = requests.post(
                'http://localhost:8000/analyze',
                files={'file': f}
            )
            result = response.json()
            # Procesar resultados...
```

## ğŸ”§ Uso ProgramÃ¡tico

### Como mÃ³dulo Python

```python
from lora_analyzer import LoRAAnalyzer, format_analysis_report

# Analizar un archivo
analyzer = LoRAAnalyzer('mi_lora.safetensors')
analysis = analyzer.analyze()

# Ver reporte formateado
print(format_analysis_report(analysis))

# Acceder a datos especÃ­ficos
rank = analysis['architecture']['rank_info']['most_common_rank']
print(f"Rank detectado: {rank}")

# Extraer metadatos
metadata = analysis['metadata']
learning_rate = metadata.get('ss_learning_rate', 'N/A')
print(f"Learning rate: {learning_rate}")
```

## ğŸ“¦ Estructura del Proyecto

```
lora-analyzer/
â”œâ”€â”€ lora_analyzer.py      # MÃ³dulo core de anÃ¡lisis
â”œâ”€â”€ lora_cli.py          # AplicaciÃ³n CLI
â”œâ”€â”€ lora_webapp.py       # AplicaciÃ³n Web (Gradio)
â”œâ”€â”€ lora_api.py          # API REST (FastAPI)
â”œâ”€â”€ requirements.txt     # Dependencias
â””â”€â”€ README.md           # Esta documentaciÃ³n
```

## ğŸ› ï¸ Requisitos del Sistema

- Python 3.8 o superior
- 4GB RAM mÃ­nimo (8GB recomendado)
- Espacio en disco: ~2GB para dependencias

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Cambiar puertos

**Web App:**
```python
# En lora_webapp.py, lÃ­nea 249
app.launch(server_port=8080)  # Cambiar de 7860 a 8080
```

**API:**
```python
# En lora_api.py, lÃ­nea 360
uvicorn.run(app, host="0.0.0.0", port=9000)  # Cambiar de 8000 a 9000
```

### AnÃ¡lisis de archivos grandes

Para LoRAs muy grandes (>1GB):

```python
# Aumentar lÃ­mite de anÃ¡lisis de capas
analyzer = LoRAAnalyzer('huge_lora.safetensors')
# Modifica _analyze_weights para analizar mÃ¡s capas
```

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas! Para reportar bugs o sugerir features, abre un issue.

## ğŸ“ Notas Importantes

1. **Privacidad**: Todo el anÃ¡lisis se hace localmente. No se envÃ­a informaciÃ³n a servidores externos.

2. **Rendimiento**: El anÃ¡lisis de archivos grandes puede tomar tiempo. La CLI es mÃ¡s rÃ¡pida que la Web App.

3. **Compatibilidad**: DiseÃ±ado principalmente para LoRAs de Stable Diffusion, pero puede funcionar con otros tipos.

4. **Metadatos**: La cantidad de informaciÃ³n disponible depende de cÃ³mo fue guardado el LoRA. LoRAs entrenados con Kohya suelen tener mÃ¡s metadatos.

## ğŸ”® Roadmap

- [ ] Soporte para anÃ¡lisis de LoRAs de LLMs
- [ ] VisualizaciÃ³n de distribuciÃ³n de pesos
- [ ] DetecciÃ³n automÃ¡tica de estilo/concepto
- [ ] Base de datos para indexar LoRAs analizados
- [ ] Exportar reportes en PDF
- [ ] IntegraciÃ³n con Hugging Face Hub

## ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible bajo la licencia MIT.

## â“ FAQ

**P: Â¿Puedo recuperar las imÃ¡genes con las que se entrenÃ³ el LoRA?**
R: No, es tÃ©cnicamente imposible. Los pesos del modelo son el resultado de la optimizaciÃ³n, pero no contienen los datos originales.

**P: Â¿Funciona con cualquier tipo de LoRA?**
R: EstÃ¡ optimizado para LoRAs de Stable Diffusion, pero puede analizar cualquier LoRA en formato safetensors o PyTorch.

**P: Â¿Por quÃ© algunos metadatos no aparecen?**
R: Depende de cÃ³mo fue guardado el archivo. Usa herramientas como Kohya que incluyen metadatos extensos.

**P: Â¿Puedo usar esto para crear LoRAs mejores?**
R: SÃ­! Analiza LoRAs exitosos para aprender quÃ© configuraciones funcionan mejor para diferentes casos de uso.

**P: Â¿Es seguro analizar LoRAs de fuentes desconocidas?**
R: El anÃ¡lisis es seguro, pero ten cuidado al cargar pesos en un modelo. Los archivos .pt y .ckpt pueden contener cÃ³digo malicioso.

## ğŸ™ Agradecimientos

Desarrollado para la comunidad de ML y entusiastas de LoRA.

---

**Â¿Preguntas o problemas?** Abre un issue en el repositorio.

**Â¿Te resultÃ³ Ãºtil?** Â¡Dale una estrella â­!
